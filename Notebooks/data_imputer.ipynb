{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed42230",
   "metadata": {},
   "source": [
    "$$\\large \\text{Packages & Specs} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7499c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "# Kalman Smoothing using R objects\n",
    "import rpy2.robjects as robjects\n",
    "# import R packages\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "# Impute TS\n",
    "imputeTS = importr('imputeTS')\n",
    "kalman_StructTs = robjects.r['na_kalman']\n",
    "\n",
    "import sys\n",
    "\n",
    "module_path = re.sub(r'Notebooks','Python Scripts',os.getcwd())\n",
    "sys.path.append(module_path)\n",
    "from pv_modules import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea4cb3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolation_method(df, nan_gaps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Performs interpolation on a DataFrame to fill missing values using the 'time' method.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "        nan_gaps (dict): Dictionary containing column names as keys and lists of NaN gap indices as values.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with filled values using time based linear interpolation.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    output_df = df.copy()\n",
    "        \n",
    "    for col in df.columns:\n",
    "        \n",
    "        if not df[col].isna().sum().sum(): continue\n",
    "\n",
    "        df[col] = df[col].interpolate(method='time', limit_direction='both')\n",
    "            \n",
    "    for col in nan_gaps.keys():\n",
    "        output_df[col].iloc[nan_gaps[col]] = df[col].iloc[nan_gaps[col]]\n",
    "            \n",
    "    \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d87ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ARIMA(df, nan_gaps):\n",
    "    \n",
    "    \"\"\"\n",
    "    Applies Kalman filtering to a DataFrame to fill missing values.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "        nan_gaps (dict): Dictionary containing column names as keys and lists of NaN gap indices as values.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with filled values using Kalman filtering.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    output_df = df.copy()\n",
    "    \n",
    "    for col in df.columns:\n",
    "        \n",
    "        arr = np.ndarray.tolist(df[col].values)\n",
    "        arr = robjects.FloatVector(arr)\n",
    "\n",
    "        df[col] = kalman_StructTs(arr, model = \"auto.arima\")\n",
    "        \n",
    "    for col in nan_gaps.keys():\n",
    "        output_df[col].iloc[nan_gaps[col]] = df[col].iloc[nan_gaps[col]]\n",
    "        \n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "605d8363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_imputer(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    Finds the index positions of gaps in a DataFrame based on their size and applies appropriate imputation method.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with filled missing values using interpolation and Kalman filtering.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    interpolation = {}\n",
    "    arima = {}\n",
    "    \n",
    "    for col in range(len(df.columns)):\n",
    "        index_list = []\n",
    "        interpolation[df.columns[col]] = []\n",
    "        arima[df.columns[col]] = []\n",
    "        for index in range(len(df.index)):\n",
    "            if index in index_list: continue\n",
    "            day = df.index[index].day\n",
    "            c = 0\n",
    "            while np.isnan(df.iloc[index+c,col]) and df.index[index+c].day == day:\n",
    "                if df.index[index+c] == df.index[-1]: break\n",
    "                index_list += [index+c]           \n",
    "                c += 1     \n",
    "            if not c and not np.isnan(df.iloc[index+c,col]): continue\n",
    "            dt = (df.index[index+c] - df.index[index]).total_seconds()\n",
    "            if dt <= 200:\n",
    "                interpolation[df.columns[col]] += list(range(index,index+c+1))\n",
    "            else:\n",
    "                arima[df.columns[col]] += list(range(index,index+c+1))\n",
    "\n",
    "        if not interpolation[df.columns[col]]:\n",
    "            del interpolation[df.columns[col]]\n",
    "        if not arima[df.columns[col]]:\n",
    "            del arima[df.columns[col]]\n",
    "            \n",
    "    if interpolation:\n",
    "        df = interpolation_method(df,interpolation)\n",
    "    if arima:\n",
    "        df = ARIMA(df,arima)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7226f6",
   "metadata": {},
   "source": [
    "$$\\large \\text{Imputer; instance of df for cleaning and preprocessing} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e992a8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer():\n",
    "    \n",
    "    \"\"\"\n",
    "    Class for data imputation and cleaning.\n",
    "    \n",
    "    Attributes:\n",
    "        df (pandas.DataFrame): Input DataFrame.\n",
    "        month (str): Month.\n",
    "        year (str): Year.\n",
    "        file (str): File type.\n",
    "\n",
    "    Methods:\n",
    "        run(): Runs the data imputation and cleaning process.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,df,month,year,file):\n",
    "        self.df = df\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.file = file\n",
    "        super().__init__()\n",
    "    def run(self):\n",
    "                \n",
    "        # === reshaping df for timestap & adjusted headers === #\n",
    "        self.df = reshape_df(self.df,self.file)\n",
    "        \n",
    "        # === filling gaps in time intervals === #\n",
    "        self.df,_ = add_missing_times(self.df)\n",
    "        \n",
    "        # === Using PvLib to remove nightime values === #\n",
    "        self.df = remove_night(self.df)\n",
    "        \n",
    "        if self.file == 'Irradiance':\n",
    "            \n",
    "            # === Set Column Names === #\n",
    "            self.df.columns = ['GlobalIR','DirectIR','DiffuseIR','WindSpeed','Temperature']\n",
    "            \n",
    "            # === Removing Misread Vemps === #\n",
    "            self.df = clean_irradiance_values(self.df)\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            # === Set Column Names === #\n",
    "            self.df.columns = ['MonoSi_Vin','MonoSi_Iin','MonoSi_Vout','MonoSi_Iout','PolySi_Vin','PolySi_Iin','PolySi_Vout','PolySi_Iout','TFSi_a_Vin','TFSi_a_Iin','TFSi_a_Vout','TFSi_a_Iout','TFcigs_Vin','TFcigs_Iin','TFcigs_Vout','TFcigs_Iout','TempF_Mono','TempF_Poly','TempF_Amor','TempF_Cigs']\n",
    "        \n",
    "            # === Removing Misread Values === #\n",
    "            self.df = clean_deger_fixed_values(self.df)\n",
    "            \n",
    "        print(f\"Imputing {round(self.df.isna().sum().sum()/self.df.size*100,3)}% of the data for {self.month}, {self.year}.\")\n",
    "\n",
    "        self.df = df_imputer(self.df)\n",
    "        \n",
    "        if self.df.isna().any().any():   \n",
    "            raise Exception(f\"The File {self.file}, {self.month} {self.year} still has NaN values\")\n",
    "            \n",
    "        cwd = re.sub(\"Notebooks|Python Scripts\",\"Data/\",os.getcwd())\n",
    "        datapath = cwd + self.year + '/' + self.file + '/'\n",
    "        file = self.month.lower() + '.csv'\n",
    "        self.df.to_csv(datapath + \"/clean_\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ec87484",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(threading.Thread):\n",
    "    \n",
    "    \"\"\"\n",
    "    Thread worker class for parallel processing.\n",
    "    \n",
    "    Attributes:\n",
    "        queue (Queue): Queue containing file paths.\n",
    "        file (str): File type.\n",
    "        lock (threading.Lock): Lock for thread synchronization.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, queue, file, lock):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.file = file\n",
    "        self.lock = lock\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            try:\n",
    "                file_path = self.queue.get(timeout=3) # retrieve file path from the queue\n",
    "            except queue.Empty:\n",
    "                return # If the queue is empty, exit the thread\n",
    "            \n",
    "            data = re.search(r\"/(\\d{4})/[a-zA-Z]*/([a-zA-Z]*)\\.csv\",file_path).group(1,2)\n",
    "            df = pd.read_csv(file_path, sep=\"\\t|,\", engine='python')\n",
    "            self.lock.acquire()\n",
    "            print('Starting',data[1], data[0])\n",
    "            self.lock.release()\n",
    "            Imputer(df, data[1], data[0], self.file).run()\n",
    "            self.lock.acquire()\n",
    "            print('Completed',data[1], data[0])\n",
    "            self.lock.release()\n",
    "            self.queue.task_done() # Notify the queue that the task is done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039b4221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File (opt: Irradiance/Deger/Fixed): Irradiance\n",
      "Starting february 2022\n",
      "Starting june 2022\n",
      "Starting jul 2022\n",
      "Starting april 2022\n",
      "Starting march 2022\n",
      "Starting january 2022\n",
      "Imputing 1.938% of the data for february, 2022.\n",
      "Imputing 0.971% of the data for june, 2022.\n",
      "Imputing 1.22% of the data for april, 2022.\n",
      "Imputing 3.861% of the data for march, 2022.\n",
      "Imputing 0.704% of the data for jul, 2022.\n",
      "Imputing 9.823% of the data for january, 2022.\n"
     ]
    }
   ],
   "source": [
    "starttime = pd.Timestamp.now()\n",
    "        \n",
    "q = queue.Queue()\n",
    "\n",
    "file = input(\"File (opt: Irradiance/Deger/Fixed): \")\n",
    "             \n",
    "file_paths = get_file_paths(file) \n",
    "\n",
    "for file_path in file_paths:\n",
    "    q.put_nowait(file_path)\n",
    "    # = run for specific month and year, or for test file = #\n",
    "#     if re.search(r'jul',file_path.lower()) and re.search(r'2022',file_path): \n",
    "#         q.put_nowait(file_path)\n",
    "    \n",
    "lock = threading.Lock()\n",
    "\n",
    "for _ in range(6): \n",
    "    t = Worker(q, file, lock)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "\n",
    "q.join() \n",
    "\n",
    "endtime = pd.Timestamp.now()\n",
    "\n",
    "runtime = endtime - starttime\n",
    "\n",
    "print(\"Start:\",starttime,\"\\nEnd:\",endtime,\"\\nRun Time:\",runtime.total_seconds())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
