{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Packages & Specs} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pvlib\n",
    "import re\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pykalman import KalmanFilter\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Kalman Smoothing using R objects\n",
    "import rpy2.robjects as robjects\n",
    "# import R packages\n",
    "from rpy2.robjects.packages import importr\n",
    "imputeTS = importr('imputeTS') \n",
    "kalman_StructTs = robjects.r['na.kalman']\n",
    "kalman_auto_arima = robjects.r['na.kalman']\n",
    "sea_decom = robjects.r['na.seadec']\n",
    "sea_split = robjects.r['na.seasplit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Loading all possible data paths} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(file):\n",
    "    path_list = []\n",
    "    datapath = re.sub(r'Notebooks','Data/',os.getcwd())\n",
    "    for dir in os.scandir(datapath):\n",
    "        if re.search(r'\\.',dir.name): continue\n",
    "        year_path = datapath + f\"{dir.name}\"\n",
    "        for dir in os.scandir(year_path):\n",
    "            if dir.name == file:\n",
    "                month_path = year_path + f\"/{dir.name}/\"\n",
    "                for dir in os.scandir(month_path):\n",
    "                    if not re.search(r'[\\.csv]|[\\.xlsx]',dir.name): continue\n",
    "                    path_list += [month_path + f\"{dir.name}\"]\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large \\text{Data Pre-Preprocessing} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Reshaping dataframe with timestamp index and feature} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df(df):\n",
    "    df['DayID'] = df['DayID'].astype(str)\n",
    "    df['TimeID'] = df['TimeID'].astype(str)\n",
    "    df['date'] = df['DayID'] + 'T' +  df['TimeID']\n",
    "    df = df.drop(columns = ['DayID','TimeID'])\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index('date')\n",
    "    df.index = df.index.tz_localize(tz = 'Etc/UTC')\n",
    "    df = df.sort_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Creating rows with NaN values where time gaps are larger than 21 seconds between observations} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_times(df):\n",
    "    \n",
    "    # creating of list of times to find interval gaps\n",
    "    time_list = list(df.index)\n",
    "    \n",
    "    # calculating interval gaps if > 21s and storing [interval length (s), start_time, end_time]\n",
    "    missing_intervals = [[(time_list[time+1] - time_list[time]).total_seconds(),time_list[time],time_list[time+1]]\n",
    "                 for time in range(len(time_list)-1) if (time_list[time+1] - time_list[time]).total_seconds() > 21]\n",
    "    # generating time stamps to fill interval gaps \n",
    "    interval_list = [element for sublist in [pd.date_range(start=interval[1],\n",
    "                             end=interval[2]-pd.Timedelta(1,'s'),\n",
    "                             freq='11s') for interval in missing_intervals] for element in sublist]\n",
    "    \n",
    "    # checking for missing values at the beginning of the month\n",
    "    if time_list[0] > time_list[0].replace(day=1,hour=1):\n",
    "        print(\"Month found with missing values at the beginning of the month.\")\n",
    "        print('Time:',time_list[0])\n",
    "        interval_list += [time for time in pd.date_range(start=time_list[0].replace(day=1,hour=0,minute=0,second=0),\n",
    "                             end=time_list[0]-pd.Timedelta(1,'s'),\n",
    "                             freq='11s')]\n",
    "        \n",
    "    # checking for missing values at the end of the month    \n",
    "    next_month = time_list[0].replace(day=28,hour=0,minute=0,second=0) + pd.Timedelta(4,'d')\n",
    "    last_day = next_month - pd.Timedelta(next_month.day,'d')\n",
    "    if time_list[-1] < last_day.replace(hour = 23,minute=0):\n",
    "        print(\"Month found with missing values at the end of the month.\")\n",
    "        print('Time:',time_list[-1])\n",
    "        interval_list += [time for time in pd.date_range(start=time_list[-1],\n",
    "                     end=last_day.replace(hour=23,minute=59,second=59),\n",
    "                     freq='11s')]\n",
    "        \n",
    "    interval_list = list(set(interval_list))\n",
    "    mt_df = pd.DataFrame(index=interval_list,columns=df.columns)\n",
    "    mt_df.loc[interval_list] = np.nan\n",
    "    df = pd.concat([df,mt_df], axis = 0).sort_index()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Removing night time observations, and irregular variable values} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_night(df):\n",
    "    lat = 49.102\n",
    "    lon = 6.215\n",
    "    alt = 220\n",
    "    solpos = pvlib.solarposition.get_solarposition(\n",
    "        time=df.index,latitude=lat,longitude=lon,altitude=alt,method='pyephem')\n",
    "    df = df[solpos['zenith'] <=90].replace(0,np.nan)\n",
    "    return df\n",
    "\n",
    "def remove_bad_temps(df):\n",
    "    df['Temperature'] = np.where((df['Temperature'] > 60)|(df['Temperature'] < 0), np.nan, df['Temperature'])\n",
    "    return df\n",
    "\n",
    "def remove_bad_wind_speeds(df):\n",
    "    df['WindSpeed'] = np.where((df['WindSpeed'] < 0)|(df['WindSpeed'] > 100), np.nan, df['WindSpeed'])\n",
    "    return df\n",
    "\n",
    "def remove_bad_dni(df):\n",
    "    df['DirectIR'] = np.where((df['DirectIR'] > 2000)|(df['DirectIR'] < 0), np.nan, df['DirectIR'])\n",
    "    return df\n",
    "\n",
    "def remove_bad_dhi(df):\n",
    "    df['DiffuseIR'] = np.where((df['DiffuseIR'] > 2000)|(df['DiffuseIR'] < 0), np.nan, df['DiffuseIR'])\n",
    "    return df\n",
    "\n",
    "def remove_neg(df):\n",
    "    df[df < 0] = np.nan\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(df):\n",
    "    \n",
    "    df['Seconds'] = [(time - time.replace(hour=0, minute=0, second=0,\n",
    "                                          microsecond=0)).total_seconds() for time in df.index]\n",
    "    df['Day'] = [d.day for d in df.index]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].isna().sum():\n",
    "            df_KNN = df[[col,'Day', 'Seconds']].copy()\n",
    "            scaler = MinMaxScaler()\n",
    "            scaled_df = pd.DataFrame(scaler.fit_transform(df_KNN), columns = df_KNN.columns)\n",
    "            imputer = KNNImputer(n_neighbors=7,weights='distance')\n",
    "            knn_solar = pd.DataFrame(imputer.fit_transform(scaled_df),\n",
    "                                    columns=scaled_df.columns)\n",
    "            inverse_knn_solar = pd.DataFrame(scaler.inverse_transform(knn_solar),\n",
    "                                columns=knn_solar.columns, index=df_KNN.index)\n",
    "            df[col] = inverse_knn_solar[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputation(df):\n",
    "    for col in range(len(df.columns)):\n",
    "        inx_ind = []\n",
    "        for index in range(len(df.index)):\n",
    "            if index in inx_ind: continue\n",
    "            c = 0\n",
    "            while np.isnan(df.iloc[index+c,col]) and df.iloc[index+c,col] != df.iloc[-1,col]:\n",
    "                inx_ind += [index+c]\n",
    "                c += 1\n",
    "            if not c: continue\n",
    "            dt = (df.index[index+c] - df.index[index]).total_seconds()\n",
    "            if dt <= 200:\n",
    "                knn_imputations += inx_ind\n",
    "            elif dt <= 10000:\n",
    "                \n",
    "    if test_gaps:\n",
    "        df = df.drop(df.iloc[test_gaps].index, axis=0)\n",
    "        copy_df = copy_df.drop(copy_df.iloc[test_gaps].index, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Dataframe cleaner function, take in file path and loads preprocessed data} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Imputer():\n",
    "    def __init__(self,df,month,year,file):\n",
    "        self.df = df\n",
    "        self.month = month\n",
    "        self.year = year\n",
    "        self.file = file\n",
    "        super().__init__()\n",
    "    def run(self):\n",
    "        # ==== reshaping df for timestap & adjusted headers ==== #\n",
    "        self.df = reshape_df(self.df)\n",
    "        \n",
    "        # === filling gaps in time intervals === #\n",
    "        self.df = add_missing_times(self.df)\n",
    "        \n",
    "        # ==== Using PvLib to remove nightime values === #\n",
    "        self.df = remove_night(self.df)\n",
    "        \n",
    "        # === Removing negative values === #  \n",
    "        self.df = remove_neg(self.df)\n",
    "        \n",
    "        if self.file == 'Irradiance':\n",
    "            # === Removing misread Temps === #\n",
    "            self.df = remove_bad_temps(self.df)\n",
    "\n",
    "            # # === Removing misread Wind Speeds === #\n",
    "            df_load = remove_bad_wind_speeds(df_load)\n",
    "\n",
    "            # # === Removing misread dni === #\n",
    "            df_load = remove_bad_dni(df_load)\n",
    "\n",
    "            # # === Removing misread dhi === #\n",
    "            df_load = remove_bad_dhi(df_load)\n",
    "\n",
    "        q = queue.Queue()\n",
    "        \n",
    "        for col in self.df.columns:\n",
    "            q.put_nowait(col)\n",
    "        \n",
    "        for _ in range(4):\n",
    "            threading.Thread(target=wrapper_targetFunc,args=(interpolate, q, self.df)).start()\n",
    "        q.join()   \n",
    "        \n",
    "        self.df['ghi'] = self.df['dhi'] + self.df['dni']\n",
    "\n",
    "        self.df = wind_speed_to_abs(self.df)\n",
    "\n",
    "        cwd = os.getcwd()\n",
    "        datapath = cwd + \"/data/\" + self.year + '/' + self.month\n",
    "        file = self.month.lower() + '.csv'\n",
    "        self.df.to_csv(datapath + \"/clean_\" + file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(threading.Thread):\n",
    "    def __init__(self, queue, file):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.file = file\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            file_path = self.queue.get()\n",
    "            self.clean_file(file_path)\n",
    "            self.queue.task_done()\n",
    "\n",
    "    def clean_file(self, file_path):\n",
    "        data = re.search(r\"/(\\d{4})/[a-z]*/([a-z]*)\\.csv\",file_path).group(1,2)\n",
    "        # Read in file\n",
    "        df = pd.read_csv(file_path, sep=\"\\t|,\", engine='python')\n",
    "        # Perform data cleaning\n",
    "        Imputer(df, data[1], data[0], self.file)\n",
    "\n",
    "starttime = datetime.now()\n",
    "        \n",
    "# initializing queue\n",
    "q = queue.Queue()\n",
    "\n",
    "file = input(\"File (opt: Irradiance/Deger/Fixed): \"\n",
    "             \n",
    "for i in range(4): # change 4 to the number of threads you want to use\n",
    "    t = Worker(q, file)\n",
    "    t.daemon = True\n",
    "    t.start()\n",
    "             \n",
    "# adding file paths to the queue\n",
    "file_paths = execute(file) # Your code for getting monthly file paths\n",
    "\n",
    "for file_path in file_paths:\n",
    "    q.put(file_path)\n",
    "\n",
    "q.join()  # Wait for all threads to finish\n",
    "\n",
    "endtime = datetime.now()\n",
    "\n",
    "runtime = endtime - starttime\n",
    "\n",
    "print(\"Start:\",starttime,\"\\nEnd:\",endtime,\"\\nRun Time:\",timedelta.__str__(runtime))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
