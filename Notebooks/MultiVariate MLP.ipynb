{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pvlib\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "import plotly.express as px\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error,r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "module_path = re.sub(r'Notebooks','Python Scripts',os.getcwd())\n",
    "sys.path.append(module_path)\n",
    "from performance_helper import *\n",
    "from ml_helper import *\n",
    "\n",
    "# from warnings import simplefilter\n",
    "# from sklearn.exceptions import ConvergenceWarning\n",
    "# simplefilter(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklego.preprocessing import RepeatingBasisFunction\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import neptune\n",
    "import neptune.integrations.sklearn as npt_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras import activations\n",
    "\n",
    "import neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from matplotlib import rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# == All Data == #\n",
    "datapath = re.sub(r'Notebooks|Python Scripts','Support Files',os.getcwd())\n",
    "\n",
    "# == Load Irradiance Data == #\n",
    "target_df = pd.read_csv(datapath + '/Irradiance.csv',index_col=0)\n",
    "target_df.index = pd.to_datetime(target_df.index)\n",
    "\n",
    "# == Load ML Data == #\n",
    "training_df = pd.read_csv(datapath + '/meteo_data_cleaned.csv',index_col=0)\n",
    "training_df.index = pd.to_datetime(training_df.index)\n",
    "\n",
    "target_df = target_df[(target_df.index.year != 2022) & (target_df.index.month != 7)]\n",
    "training_df = training_df[(training_df.index.year != 2022) & (training_df.index.month != 7)]\n",
    "training_df = training_df[training_df.index.isin(target_df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(training_df)\n",
    "print(target_df)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "starttime = pd.Timestamp.now()\n",
    "# ======= Any Model ======= #\n",
    "\n",
    "df = target_df.dropna()\n",
    "\n",
    "test_ml_df = training_df[training_df.index.isin(df.index)].copy()\n",
    "\n",
    "test_ml_df = pd.concat([test_ml_df,df],axis=1,ignore_index=False)\n",
    "\n",
    "test_ml_df = shuffle(test_ml_df)\n",
    "\n",
    "X = test_ml_df.drop(df.columns, axis = 1).to_numpy()\n",
    "y = test_ml_df.drop(training_df.columns, axis = 1).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)\n",
    "\n",
    "\n",
    "# == Activation Function == #\n",
    "#     activation = activations.relu\n",
    "#     activation = activations.tanh\n",
    "#     activation = activations.selu\n",
    "#     activation = activations.elu\n",
    "#     activation = activations.sigmoid\n",
    "#     activation = activations.softmax\n",
    "#     activation = activations.softplus\n",
    "#     activation = activations.softsign\n",
    "\n",
    "# == Optomization Parameters = #\n",
    "hidden_layer_sizes = (300,200,150)\n",
    "learning_rate_ = 0.0001\n",
    "alpha = 0.0001\n",
    "beta_1_ = 0.9\n",
    "beta_2_ = 0.999\n",
    "epsilon_ = 1e-7\n",
    "# == Optomization Parameters = #\n",
    "\n",
    "# == Solver == #\n",
    "#     solver = tf.keras.optimizers.Adam(learning_rate=learning_rate_, beta_1 = beta_1_, beta_2= beta_2_,\n",
    "#                                                     epsilon = epsilon_, amsgrad = True, name = \"Adam\")\n",
    "# solver = tf.keras.optimizers.Adam(learning_rate=learning_rate_,name = \"Adam\")\n",
    "#     solver = tf.keras.optimizers.experimental.AdamW(learning_rate=learning_rate_, name = 'AdamW')\n",
    "#     solver = tf.keras.optimizers.Adamax()\n",
    "#     solver = tf.keras.optimizers.SGD() # horrible\n",
    "solver = tf.keras.optimizers.RMSprop()\n",
    "\n",
    "x_shape, y_shape = training_df.shape\n",
    "# == Solver == #\n",
    "\n",
    "# == Model == #\n",
    "multi_model = keras.models.Sequential([\n",
    "    keras.layers.Input(shape = (y_shape,), name='MultiOutput-MLP'),\n",
    "\n",
    "#         keras.layers.ReLU(name = 'Activation-Layer-1'),\n",
    "\n",
    "    keras.layers.Dense(hidden_layer_sizes[0],\n",
    "                       kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "                       activation = 'relu',\n",
    "                       name = 'Hidden-Layer-1'),\n",
    "\n",
    "#         keras.layers.ReLU(name = 'Activation-Layer-2'),\n",
    "#         keras.optimizers.Nadam(),\n",
    "\n",
    "    keras.layers.Dense(hidden_layer_sizes[1],\n",
    "                       kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "                       activation = 'relu',\n",
    "                       name = 'Hidden-Layer-2'),\n",
    "    \n",
    "    keras.layers.Dense(hidden_layer_sizes[1],\n",
    "                       kernel_initializer=tf.keras.initializers.HeNormal(),\n",
    "                       activation = 'relu',\n",
    "                       name = 'Hidden-Layer-3'),\n",
    "\n",
    "    keras.layers.Dense(len(df.columns), name = \"Output-Layer\")\n",
    "])\n",
    "\n",
    "multi_model.compile(optimizer=solver,\n",
    "              loss='mean_absolute_error',\n",
    "              metrics=['mean_absolute_error'])\n",
    "# == Model == #\n",
    "\n",
    "# == callbacks == #\n",
    "overfitting = EarlyStopping(monitor = 'loss', min_delta = 0, patience = 20)\n",
    "learning_rate = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-3 * 10 ** (epoch / 20))\n",
    "logdir = \"logs/fit/\" + pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tb = TensorBoard(log_dir = logdir, histogram_freq = 1)\n",
    "# == callbacks == #\n",
    "\n",
    "# == Local Fit == #\n",
    "# multi_history = multi_model.fit(X_train,\n",
    "#                     y_train,\n",
    "#                     epochs = 10,\n",
    "# #                     batch_size = 3000,\n",
    "#                     validation_data = (X_test, y_test),\n",
    "#                     callbacks = [overfitting,\n",
    "#                                  tb]\n",
    "#                    )\n",
    "\n",
    "# == Neptune Fit == #\n",
    "run = neptune.init_run(\n",
    "    project=\"ethanmasters/PV-Solar-MLP\",\n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIyMWZhYmFiYi0zYWEzLTQ3NTMtYmMyOS1jZjAzYjY0N2EwYjgifQ==\",\n",
    "    name=\"MLP-DiffuseIR\",\n",
    "    tags=[\"MLPRegressor\", \"regression\", \"MultiOutput\"],\n",
    "    )\n",
    "multi_history = multi_model.fit(X_train, \n",
    "                    y_train, \n",
    "                    epochs = 100, \n",
    "#                         batch_size = 50,\n",
    "                    validation_data = (X_test, y_test),\n",
    "                    callbacks = [NeptuneCallback(run = run, log_model_diagram = True),\n",
    "                                overfitting,\n",
    "                                tb]\n",
    "                   )\n",
    "# == Neptune Fit == #\n",
    "\n",
    "# == serialize model == #\n",
    "multi_model.save(f\"multivariate_mlp_model\")\n",
    "\n",
    "multi_model.summary()\n",
    "\n",
    "endtime = pd.Timestamp.now()\n",
    "runtime = endtime - starttime\n",
    "print(\"Run Time:\", runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = multi_history.history\n",
    "model = multi_model1\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose = 1)\n",
    "print(score)\n",
    "\n",
    "model_df = pd.DataFrame(history)\n",
    "mse_df = model_df[['mean_absolute_error','val_mean_absolute_error']]\n",
    "mse_df.plot(figsize=(12,6))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.show()\n",
    "\n",
    "\n",
    "loss_df = model_df[['loss','val_loss']]\n",
    "loss_df.plot(figsize=(12,6))\n",
    "plt.grid(True)\n",
    "# plt.gca().set_ylim(0,1) # set the vertical range to [0-1]\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import dalex as dx\n",
    "X, y = pd.DataFrame(X_test, columns = test_ml_df.columns), y_test\n",
    "exp = dx.Explainer(model, X, y, label=col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp.model_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_parts().plot()\n",
    "run[\"model/performance/model_parts\"].upload(exp.model_parts().plot(show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_profile().plot()\n",
    "run[\"model/performance/model_profile\"].upload(exp.model_profile().plot(show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_diagnostics().plot()\n",
    "run[\"model/performance/model_diagnostics\"].upload(exp.model_diagnostics().plot(show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "exp.model_diagnostics().result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# surrogate_model = explainer.model_surrogate(max_vars=4, max_depth=3)\n",
    "surrogate_model = exp.model_surrogate()\n",
    "surrogate_model.performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "surrogate_model.plot()\n",
    "# run[\"model/performance/surrogate_model\"].upload(surrogate_model.plot(show=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
