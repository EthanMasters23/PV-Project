{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Packages \\& Specs} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pvlib\n",
    "import re\n",
    "import json\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Loading all possible paths for Irradiance files} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute(file):\n",
    "    path_list = []\n",
    "    datapath = re.sub(r'Notebooks|Python Scripts','Data/',os.getcwd())\n",
    "    for dir in os.scandir(datapath):\n",
    "        if re.search(r'\\.',dir.name): continue\n",
    "        year_path = datapath + f\"{dir.name}\"\n",
    "        for dir in os.scandir(year_path):\n",
    "            if dir.name == file:\n",
    "                month_path = year_path + f\"/{dir.name}/\"\n",
    "                for dir in os.scandir(month_path):\n",
    "                    if not re.search(r'\\.csv|\\.xlsx',dir.name): continue\n",
    "                    path_list += [month_path + f\"{dir.name}\"]\n",
    "    return path_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Path function for returning input files} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_func(year,month,path_list,file):\n",
    "    path_found = []\n",
    "    for path in path_list:\n",
    "        y,m = re.search(r\"/(\\d{4})/[a-z]*/([a-z]*)\\.\",path.lower()).group(1,2)\n",
    "        if re.search(fr\"{year}\",y) and re.search(fr\"{month}\",m):\n",
    "            path_found += [path]\n",
    "            break\n",
    "\n",
    "    print(f\"Summary of data for {file} in {m}, {y} \\n\")\n",
    "    return path_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large \\text{Data Pre-Preprocessing} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Reshaping dataframe with timestamp index and feature} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_df(df,file):\n",
    "    df['DayID'] = df['DayID'].astype(str)\n",
    "    df['TimeID'] = df['TimeID'].astype(str)\n",
    "    df['date'] = df['DayID'] + 'T' +  df['TimeID']\n",
    "    df = df.drop(columns = ['DayID','TimeID'])\n",
    "    df.date = pd.to_datetime(df.date)\n",
    "    df = df.set_index('date')\n",
    "    df.index = df.index.tz_localize(tz = 'Etc/UTC')\n",
    "    df = df.sort_index()\n",
    "    if file == 'Irradiance':\n",
    "        df.columns = ['GlobalIR','DirectIR','DiffuseIR','WindSpeed','Temperature']\n",
    "    else:\n",
    "        df.columns = ['MonoSi_Vin','MonoSi_Iin','MonoSi_Vout','MonoSi_Iout','PolySi_Vin','PolySi_Iin','PolySi_Vout','PolySi_Iout','TFSi_a_Vin','TFSi_a_Iin','TFSi_a_Vout','TFSi_a_Iout','TFcigs_Vin','TFcigs_Iin','TFcigs_Vout','TFcigs_Iout','TempF_Mono','TempF_Poly','TempF_Amor','TempF_Cigs']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Creating rows with NaN values where time intervals are greater than greater than 21 seconds} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_times(df):\n",
    "    \n",
    "    # creating of list of times to find interval gaps\n",
    "    time_list = list(df.index)\n",
    "    \n",
    "    # calculating interval gaps if > 21s and storing [interval length (s), start_time, end_time]\n",
    "    missing_intervals = [[(time_list[time+1] - time_list[time]).total_seconds(),time_list[time],time_list[time+1]]\n",
    "                 for time in range(len(time_list)-1) if (time_list[time+1] - time_list[time]).total_seconds() > 21]\n",
    "    # generating time stamps to fill interval gaps \n",
    "    interval_list = [element for sublist in [pd.date_range(start=interval[1],\n",
    "                             end=interval[2]-pd.Timedelta(1,'s'),\n",
    "                             freq='11s') for interval in missing_intervals] for element in sublist]\n",
    "    \n",
    "    # checking for missing values at the beginning of the month\n",
    "    if time_list[0] > time_list[0].replace(day=1,hour=1):\n",
    "        print(\"Found a month that has missing values in the beginning of the month.\")\n",
    "        print('Time:',time_list[0])\n",
    "        interval_list += [time for time in pd.date_range(start=time_list[0].replace(day=1,hour=0,minute=0,second=0),\n",
    "                             end=time_list[0]-pd.Timedelta(1,'s'),\n",
    "                             freq='11s')]\n",
    "        missing_intervals += [[(time_list[0] - time_list[0].replace(day=1,hour=0,minute=0,second=0)).total_seconds(),\n",
    "                             time_list[0].replace(day=1,hour=0,minute=0,second=0),time_list[0]]]\n",
    "        \n",
    "    # checking for missing values at the end of the month    \n",
    "    next_month = time_list[0].replace(day=28,hour=0,minute=0,second=0) + pd.Timedelta(4,'d')\n",
    "    last_day = next_month - pd.Timedelta(next_month.day,'d')\n",
    "    if time_list[-1] < last_day.replace(hour = 23,minute=0):\n",
    "        print(\"Found a month that has missing values in the end of the month.\")\n",
    "        print('Time:',time_list[-1])\n",
    "        interval_list += [time for time in pd.date_range(start=time_list[-1],\n",
    "                     end=last_day.replace(hour=23,minute=59,second=59),\n",
    "                     freq='11s')]\n",
    "        missing_intervals += [[(last_day.replace(hour=23,minute=59,second=59) - time_list[-1]).total_seconds(),\n",
    "                             time_list[-1],last_day.replace(hour=23,minute=59,second=59)]]\n",
    "        \n",
    "    interval_list = list(set(interval_list))\n",
    "    mt_df = pd.DataFrame(index=interval_list,columns=df.columns)\n",
    "    mt_df.loc[interval_list] = np.nan\n",
    "    df = pd.concat([df,mt_df], axis = 0).sort_index()\n",
    "\n",
    "    return df,missing_intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Creating a discrete time feature to compare observations between days} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features(df):\n",
    "    df['day'] = [d.day for d in df.index]\n",
    "    df['month'] = [d.month for d in df.index]\n",
    "    df['year'] = [d.year for d in df.index]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Removing night time observations, and irregular air tempature & wind speed values} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_night(df):\n",
    "    lat = 49.102\n",
    "    lon = 6.215\n",
    "    alt = 220\n",
    "    solpos = pvlib.solarposition.get_solarposition(\n",
    "        time=df.index,latitude=lat,longitude=lon,altitude=alt,method='pyephem')\n",
    "    df = df[solpos['zenith'] <= 90]\n",
    "    return df\n",
    "\n",
    "def irr(df):\n",
    "    # Removing Temperature Values #\n",
    "    df[df['Temperature'] > 60] = np.nan\n",
    "\n",
    "    # Removing Wind Speed Values #\n",
    "    df[df['WindSpeed'] > 100] = np.nan\n",
    "\n",
    "    # Removing DirectIR Values #\n",
    "    df[df['DirectIR'] > 2000] = np.nan\n",
    "\n",
    "    # Removing DiffuseIR Values #\n",
    "    df[df['DiffuseIR'] > 2000] = np.nan\n",
    "\n",
    "    # Removing Negative Values #\n",
    "    df[df < 0] = np.nan\n",
    "\n",
    "    return df\n",
    "\n",
    "def deg_fix(df):\n",
    "    # Removing Negative Values #\n",
    "    df[df < 0] = np.nan\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Dataframe Cleaner} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_cleaning(path_list,file):\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    outlier_output = pd.DataFrame()\n",
    "\n",
    "    missing_intervals = []\n",
    "\n",
    "    for path in path_list:\n",
    "\n",
    "        df_load = pd.read_csv(path,sep=\"\\t|,\",engine='python')\n",
    "        \n",
    "        if df_load.empty:\n",
    "            raise Exception(f\"The path: {path} loaded an empty dataframe.\")\n",
    "        \n",
    "        # ==== reshaping df for timestap & adjusted headers ==== #\n",
    "        df_load = reshape_df(df_load,file)\n",
    "        \n",
    "        # === copy df for outlier pre-processed === #\n",
    "        outlier_output = pd.concat([outlier_output,df.copy()],axis=0,ignore_index=False)\n",
    "\n",
    "        # === filling gaps in time intervals === #\n",
    "        df_load,m_intervals = add_missing_times(df_load)\n",
    "\n",
    "        # === Time Features === #\n",
    "        df_load = time_features(df_load)\n",
    "\n",
    "        # # ==== Using PvLib to remove nightime values === #\n",
    "        df_load = remove_night(df_load)\n",
    "        \n",
    "        if file == 'Irradiance':\n",
    "            df_load = irr(df_load)\n",
    "        else:\n",
    "            df_load = deg_fix(df_load)\n",
    "        \n",
    "        df = pd.concat([df,df_load],axis=0,ignore_index=False).sort_index()\n",
    "        missing_intervals += m_intervals\n",
    "    \n",
    "    return df, missing_intervals, outlier_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large \\text{Summary of NaN Values} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_nan(df):\n",
    "    total_nan = df.drop(['day','month','year'],axis=1).isna().sum().sum()\n",
    "    total_values = df.drop(['day','month','year'],axis=1).size\n",
    "    mt_count = df.drop(['day','month','year'],axis=1).isna().all(axis=1).sum()\n",
    "    t_perc = round(total_nan/total_values * 100,3)\n",
    "    mt_perc = round(mt_count*len(df.columns)/total_values * 100,3)\n",
    "\n",
    "    print(f\"Percentage of NaN values due to System Outage: {mt_perc}% \\n\")\n",
    "    \n",
    "    print(f\"Precentage of MAR NaN values: {round(t_perc-mt_perc,3)}% \\n\")\n",
    "\n",
    "    print(f\"Precentage of Total NaN values: {t_perc}%\")\n",
    "\n",
    "    print(\"\\n Missing values by column\")\n",
    "\n",
    "    for col in df.columns:\n",
    "        if not col in ['day','month','year']:\n",
    "            n_miss = df[col].isna().sum()\n",
    "            perc = round(n_miss / df.shape[0] * 100,3)\n",
    "            print(f\"{col}, Missing: {n_miss} ({perc}%)\")\n",
    "\n",
    "    print(\"\\n Missing values by day\")\n",
    "\n",
    "    for row in df['day'].unique():\n",
    "        n_miss = df[df['day']==row].drop(['day','month','year'],axis=1).isna().sum().sum()\n",
    "        perc = round(n_miss / df[df['day']==row].drop(['day','month','year'],axis=1).size * 100,3)\n",
    "        print(f\"{row}, Missing: {n_miss} ({perc}%)\")\n",
    "\n",
    "    print(\"\\n Missing values by month\")    \n",
    "\n",
    "\n",
    "    for row in sorted(df['month'].unique()):\n",
    "        if len(df['month'].unique()) == 1: break\n",
    "        n_miss = df[df['month']==row].drop(['day','month','year'],axis=1).isna().sum().sum()\n",
    "        perc = round(n_miss / df[df['month']==row].drop(['day','month','year'],axis=1).size * 100,3)\n",
    "        print(f\"{row}, Missing: {n_miss} ({perc}%)\")\n",
    "\n",
    "    print(\"\\n Missing values by year\")    \n",
    "\n",
    "\n",
    "    for row in df['year'].unique():\n",
    "        if len(df['year'].unique()) == 1: break\n",
    "        n_miss = df[df['year']==row].drop(['day','month','year'],axis=1).isna().sum().sum()\n",
    "        perc = round(n_miss / df[df['year']==row].drop(['day','month','year'],axis=1).size * 100,3)\n",
    "        print(f\"{row}, Missing: {n_miss} ({perc}%) \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Scatter plot of time intervals that were recorded as missing times} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mt_fig(missing_intervals):\n",
    "    interval_df = pd.DataFrame(missing_intervals,\n",
    "                               columns=['seconds','start_time','end_time'])\n",
    "    px.scatter(interval_df, x='start_time',y='seconds',\n",
    "               hover_data=['start_time','end_time'],\n",
    "               title='Intervals in Time of Missing Observations').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Scatter plot of all variables over time} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def col_fig(df):\n",
    "    for col in df.drop(['day','month','year'],axis=1).columns:\n",
    "        px.scatter(df, x=df.index, y=f'{col}',title=f'{col}').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Scatter plot of timestamps} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestamps_fig(df):\n",
    "    df['Seconds'] = [(time - time.replace(hour=0, minute=0,\n",
    "                                          second=0, microsecond=0)).total_seconds()for time in df.index]\n",
    "    df = df.dropna(axis=0)   \n",
    "    px.scatter(df, y='Seconds').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Correlation Matrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_matrix(df):\n",
    "    df = df.drop(['day','month','year'],axis=1)\n",
    "    df = df.dropna()\n",
    "    \n",
    "    corrs = []\n",
    "    p_values = []\n",
    "    \n",
    "    for feat1 in df.columns:\n",
    "        corr_list = []\n",
    "        p_list = []\n",
    "        for feat2 in df.columns:\n",
    "            corr, p_value = scipy.stats.spearmanr(df[feat1], df[feat2])\n",
    "            corr_list += [corr]\n",
    "            p_list += [p_value]\n",
    "        corrs += [corr_list]\n",
    "        p_values += [p_list]\n",
    "        \n",
    "    corr_matrix = pd.DataFrame(corrs, index = df.columns, columns = df.columns)\n",
    "    px.imshow(corr_matrix,text_auto=True,title=\"Correlation Matrix\").show()\n",
    "    \n",
    "    p_matrix = pd.DataFrame(p_values, index = df.columns, columns = df.columns)\n",
    "    px.imshow(p_matrix,text_auto=True,title=\"P Value Matrix\").show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Summary of outliers by variable} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def outliers(df,pre):\n",
    "    indicator = True\n",
    "    if pre: df = df.drop(['day','month','year'],axis=1)\n",
    "    for col in df.columns:\n",
    "        arr = df[col]\n",
    "        z_scores = np.abs((arr - arr.mean()) / arr.std())\n",
    "        threshold = 3\n",
    "        outliers = arr[z_scores > threshold]\n",
    "        if len(outliers):\n",
    "            indicator = False\n",
    "            print(f\"{col} number of outliers {len(outliers)}, min: {min(outliers)}, max: {max(outliers)} \\n\")\n",
    "    if indicator: print(\"There were no outliers found pre-processing. \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Figure of NaN Gaps} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_gaps(df):\n",
    "    nan_gaps = []\n",
    "    for col in range(len(df.columns)):\n",
    "        inx_ind = []\n",
    "        for index in range(len(df.index)):\n",
    "            if index in inx_ind: continue\n",
    "            c = 0\n",
    "            while np.isnan(df.iloc[index+c,col]) and df.iloc[index+c].name != df.iloc[-1].name:\n",
    "                inx_ind += [index+c]\n",
    "                c += 1\n",
    "            if not c: continue\n",
    "            dt = (df.index[index+c] - df.index[index]).total_seconds()\n",
    "            nan_gaps += [[dt, df.index[index], df.index[index+c], col]]\n",
    "    nan_df = pd.DataFrame(nan_gaps, columns = ['Seconds', 'Start Time', 'End Time', 'Column'])\n",
    "    px.scatter(nan_df, x = nan_df.index, y = 'Seconds', hover_data = ['Start Time','End Time', 'Column']\n",
    "                     ,title = 'Scatter plot of the NaN gaps (in seconds) over time:').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Summary Function Calls} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(path_list,file,update=False):\n",
    "    \n",
    "    # removing and preprocessing df\n",
    "    if update:\n",
    "        datapath = re.sub(r'Notebooks|Python Scripts','Support Files/',os.getcwd())\n",
    "        df = pd.read_csv(datapath + f'{file}_Dataframe.csv', index_col='Unnamed: 0')\n",
    "        df.index = pd.to_datetime(df.index)\n",
    "        outlier_output = pd.read_csv(datapath + f'{file}_Outlier_Dataframe.csv', index_col='Unnamed: 0')\n",
    "        with open(datapath + f\"mi_{file}.json\", \"r\") as read_file:\n",
    "            missing_intervals = json.load(read_file)\n",
    "        missing_intervals = [[interval[0],pd.to_datetime(interval[1]),\n",
    "                              pd.to_datetime(interval[2])] for interval in missing_intervals]\n",
    "    else:\n",
    "        df, missing_intervals, outlier_output = df_cleaning(path_list,file)\n",
    "    \n",
    "    # printing Summary of NaN Values\n",
    "    print(\"\\nSummary of NaN Values\")\n",
    "    summarize_nan(df)\n",
    "\n",
    "    # printing outliers pre-processing\n",
    "    print(\"Summary of outliers (if any) for pre-processed data:\")\n",
    "    outliers(outlier_output,pre = False)\n",
    "\n",
    "    # printing outliers post-processing\n",
    "    print(\"Summary of outliers (if any) for post-processed data:\")\n",
    "    outliers(df,pre = True)\n",
    "    \n",
    "    # Figure of nan gaps\n",
    "    print('Scatter plot of the NaN gaps (in seconds) over time:')\n",
    "    # too computational heavy\n",
    "#     nan_gaps(df)\n",
    "\n",
    "    # figure of missing intverals \n",
    "    print(\"Scatter plot of the system outage (in seconds) over time:\")\n",
    "    mt_fig(missing_intervals)\n",
    "\n",
    "    # figure's of all variables plotted over time\n",
    "    print(\"Figure's of all variables plotted over time:\")\n",
    "    col_fig(df)\n",
    "    \n",
    "    # figure of correlation matrix\n",
    "    print(\"Correlation Matrix:\")\n",
    "    corr_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Update Function} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(path_list, file):\n",
    "    datapath = re.sub(r'Notebooks|Python Scripts','Support Files/',os.getcwd())\n",
    "    df, missing_intervals, outlier_output = df_cleaning(path_list,file)\n",
    "    outlier_output.to_csv(datapath + fr'{file}_Outlier_Dataframe.csv')\n",
    "    df.to_csv(datapath + fr'{file}_Dataframe.csv')\n",
    "    missing_intervals = [[interval[0],str(interval[1]),str(interval[2])] for interval in missing_intervals]\n",
    "    with open(datapath + fr\"mi_{file}.json\", \"w\") as write_file:\n",
    "        json.dump(missing_intervals, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\large \\text{Main Function} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(year,month,file):\n",
    "    if not [file_i for file_i in ['Irradiance','Deger','Fixed'] if re.search(fr'{file}',file_i)]:\n",
    "            raise Exception(f\"Incorret Input: File\")\n",
    "    elif not year and not month:\n",
    "        path_list = execute(file)\n",
    "        response = input(\"Last update: April 1st 2023 \\n To continue press: 'Enter' \\n Else type: 'update()' \\n\\t\")\n",
    "        if not response:\n",
    "            summary(path_list,file,update=False)\n",
    "        elif response == \"update()\":\n",
    "            update(path_list, file)\n",
    "            summary(path_list,file,update=False)\n",
    "    elif not re.search(r'\\d{4}',year):\n",
    "        raise Exception(f\"Incorret Input: Year\")\n",
    "    elif not re.search(r'[A-Za-z]{3}',month):\n",
    "        raise Exception(f\"Incorret Input: Month\")\n",
    "    else:\n",
    "        path_list = execute(file)\n",
    "        path_list = path_func(year,month,path_list,file)\n",
    "        summary(path_list,file)\n",
    "\n",
    "main(year = input(\"Year (format: YYYY): \"), month = input(\"Month (format: jul): \"),\n",
    "     file = input(\"File (opt: Irradiance/Deger/Fixed): \"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
